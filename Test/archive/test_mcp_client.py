#!/usr/bin/env python3
"""
Test MCP PDF processing using MCP client to connect to running server.
"""

import os
import sys
import asyncio
import json
from datetime import datetime

# Add the src directory to the Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.config.language_config import LanguageConfigFactory


async def test_mcp_client_pdf_processing():
    """Test PDF processing using MCP client to connect to running server."""
    
    print("ğŸ§ª Testing MCP Client PDF Processing")
    print("=" * 50)
    
    try:
        # Try to import MCP client
        try:
            from mcp import ClientSession, StdioServerParameters
            from mcp.client.stdio import stdio_client
            MCP_AVAILABLE = True
        except ImportError:
            print("âŒ MCP client not available")
            return False
        
        print("âœ… MCP client available")
        
        # Test the PDF processing using the running MCP server
        pdf_path = "data/Classical Chinese Sample 22208_0_8.pdf"
        
        if not os.path.exists(pdf_path):
            print(f"âŒ PDF file not found: {pdf_path}")
            return False
        
        print(f"ğŸ“„ Processing PDF: {pdf_path}")
        
        # Since we can't easily connect to the HTTP MCP server from here,
        # let's test the PDF processing using the existing agents directly
        print("\nğŸ”¬ Testing PDF processing using existing agents...")
        
        from src.agents.enhanced_file_extraction_agent import EnhancedFileExtractionAgent
        from src.agents.knowledge_graph_agent import KnowledgeGraphAgent
        from src.core.models import AnalysisRequest, DataType
        
        # Step 1: Extract text
        print("ğŸ“„ Step 1: Extracting text from PDF...")
        file_agent = EnhancedFileExtractionAgent()
        
        pdf_request = AnalysisRequest(
            data_type=DataType.PDF,
            content=pdf_path,
            language="zh"
        )
        
        extraction_result = await file_agent.process(pdf_request)
        
        if extraction_result.status != "completed":
            print(f"âŒ Text extraction failed: {extraction_result.metadata.get('error', 'Unknown error')}")
            return False
        
        text_content = extraction_result.extracted_text
        print(f"âœ… Text extraction successful: {len(text_content)} characters")
        
        # Step 2: Check for Classical Chinese patterns
        print("ğŸ›ï¸ Step 2: Checking for Classical Chinese patterns...")
        chinese_config = LanguageConfigFactory.get_config("zh")
        
        if hasattr(chinese_config, 'is_classical_chinese'):
            is_classical = chinese_config.is_classical_chinese(text_content[:1000])
            print(f"âœ… Classical Chinese detected: {is_classical}")
        
        # Step 3: Process with knowledge graph agent
        print("ğŸ§  Step 3: Processing with knowledge graph agent...")
        kg_agent = KnowledgeGraphAgent()
        
        kg_request = AnalysisRequest(
            data_type=DataType.TEXT,
            content=text_content,
            language="zh"
        )
        
        kg_result = await kg_agent.process(kg_request)
        
        if kg_result.status != "completed":
            print(f"âŒ Knowledge graph processing failed: {kg_result.metadata.get('error', 'Unknown error')}")
            return False
        
        # Step 4: Generate report
        print("ğŸ“Š Step 4: Generating knowledge graph report...")
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = f"Results/reports/mcp_client_test_{timestamp}"
        
        os.makedirs("Results/reports", exist_ok=True)
        
        report_result = await kg_agent.generate_graph_report(
            output_path=output_path,
            target_language="zh"
        )
        
        # Compile results
        stats = kg_result.metadata.get("statistics", {}) if kg_result.metadata else {}
        
        result = {
            "success": True,
            "method": "mcp_client_agents",
            "pdf_path": pdf_path,
            "language": "zh",
            "text_extraction": {
                "success": True,
                "content_length": len(text_content),
                "pages_processed": len(extraction_result.pages) if extraction_result.pages else 'Unknown',
                "extraction_method": "Enhanced multilingual"
            },
            "entity_extraction": {
                "entities_found": stats.get('entities_found', 0),
                "entity_types": stats.get('entity_types', {}),
                "language_stats": stats.get('language_stats', {}),
                "extraction_method": "Enhanced multilingual with Classical Chinese support"
            },
            "knowledge_graph": {
                "nodes": stats.get('nodes', 0),
                "edges": stats.get('edges', 0),
                "communities": stats.get('communities', 0),
                "processing_time": kg_result.processing_time
            },
            "report_files": {
                "output_path": output_path,
                "success": hasattr(report_result, 'success') and report_result.success
            },
            "enhanced_features": {
                "language_specific_patterns": True,
                "dictionary_lookup": True,
                "llm_based_extraction": True,
                "classical_chinese_support": True,
                "multilingual_support": ["en", "ru", "zh"]
            }
        }
        
        print("âœ… PDF processing completed successfully!")
        
        # Display results
        print("\n" + "=" * 50)
        print("ğŸ“‹ PROCESSING RESULTS")
        print("=" * 50)
        
        print(f"ğŸ“„ PDF Path: {result['pdf_path']}")
        print(f"ğŸŒ Language: {result['language']}")
        
        # Text extraction results
        text_extraction = result['text_extraction']
        print(f"\nğŸ“„ Text Extraction:")
        print(f"   - Success: {text_extraction['success']}")
        print(f"   - Content length: {text_extraction['content_length']} characters")
        print(f"   - Pages processed: {text_extraction['pages_processed']}")
        print(f"   - Extraction method: {text_extraction['extraction_method']}")
        
        # Entity extraction results
        entity_extraction = result['entity_extraction']
        print(f"\nğŸ” Entity Extraction:")
        print(f"   - Entities found: {entity_extraction['entities_found']}")
        print(f"   - Entity types: {entity_extraction['entity_types']}")
        print(f"   - Language stats: {entity_extraction['language_stats']}")
        print(f"   - Extraction method: {entity_extraction['extraction_method']}")
        
        # Knowledge graph results
        knowledge_graph = result['knowledge_graph']
        print(f"\nğŸ§  Knowledge Graph:")
        print(f"   - Nodes: {knowledge_graph['nodes']}")
        print(f"   - Edges: {knowledge_graph['edges']}")
        print(f"   - Communities: {knowledge_graph['communities']}")
        print(f"   - Processing time: {knowledge_graph['processing_time']:.2f} seconds")
        
        # Report results
        report_files = result['report_files']
        print(f"\nğŸ“Š Report Generation:")
        print(f"   - Output path: {report_files['output_path']}")
        print(f"   - Success: {report_files['success']}")
        
        # Enhanced features
        enhanced_features = result['enhanced_features']
        print(f"\nğŸš€ Enhanced Features:")
        for feature, enabled in enhanced_features.items():
            status = "âœ…" if enabled else "âŒ"
            print(f"   - {feature}: {status}")
        
        # Save results
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        results_file = f"Results/mcp_client_test_results_{timestamp}.json"
        
        os.makedirs("Results", exist_ok=True)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ Results saved to: {results_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error testing MCP client PDF processing: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_chinese_config():
    """Test Chinese language configuration."""
    print("\nğŸ›ï¸ Testing Chinese Language Configuration")
    print("=" * 50)
    
    try:
        chinese_config = LanguageConfigFactory.get_config("zh")
        print("âœ… Chinese language configuration loaded")
        
        # Check Classical Chinese patterns
        if hasattr(chinese_config, 'classical_patterns'):
            print(f"âœ… Classical Chinese patterns: {len(chinese_config.classical_patterns)} categories")
        
        if hasattr(chinese_config, 'is_classical_chinese'):
            print("âœ… Classical Chinese detection method available")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error testing Chinese config: {e}")
        return False


async def main():
    """Main test function."""
    print("ğŸ§ª MCP Client PDF Processing Test")
    print("=" * 60)
    
    # Test Chinese configuration
    config_success = await test_chinese_config()
    
    if config_success:
        # Test MCP client PDF processing
        mcp_success = await test_mcp_client_pdf_processing()
        
        if mcp_success:
            print("\nğŸ‰ All tests completed successfully!")
        else:
            print("\nâŒ MCP client PDF processing test failed.")
    else:
        print("\nâŒ Chinese configuration test failed.")


if __name__ == "__main__":
    asyncio.run(main())
