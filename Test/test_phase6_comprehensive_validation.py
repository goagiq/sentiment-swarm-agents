"""
Phase 6: Comprehensive Testing & Validation for Multilingual Knowledge Graph
Tests all aspects of the multilingual functionality including Chinese content, 
language detection, entity extraction, query translation, performance, and integration.
"""

import asyncio
import sys
import time
import json
from pathlib import Path
from typing import Dict, List, Tuple

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.agents.knowledge_graph_agent import KnowledgeGraphAgent
from src.core.models import AnalysisRequest, DataType


class Phase6TestSuite:
    """Comprehensive test suite for Phase 6 validation."""
    
    def __init__(self):
        self.agent = KnowledgeGraphAgent()
        self.results = {}
        
    async def test_6_1_chinese_content_test_cases(self) -> Dict:
        """Task 6.1: Create Chinese content test cases."""
        print("ğŸ§ª Task 6.1: Testing Chinese Content Test Cases")
        print("=" * 60)
        
        # Comprehensive Chinese test content
        chinese_test_cases = [
            {
                "name": "Chinese News Article",
                "content": """
                ä¸­å›½ç§‘æŠ€å·¨å¤´é˜¿é‡Œå·´å·´é›†å›¢ä»Šæ—¥å®£å¸ƒï¼Œå°†åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸæŠ•èµ„1000äº¿å…ƒäººæ°‘å¸ã€‚
                è¯¥å…¬å¸CEOå¼ å‹‡è¡¨ç¤ºï¼ŒAIæŠ€æœ¯å°†åœ¨ç”µå•†ã€äº‘è®¡ç®—ã€é‡‘èç§‘æŠ€ç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚
                æ¸…åå¤§å­¦å’ŒåŒ—äº¬å¤§å­¦çš„ä¸“å®¶å›¢é˜Ÿå°†å‚ä¸æ­¤æ¬¡åˆä½œé¡¹ç›®ã€‚
                é¢„è®¡è¯¥é¡¹ç›®å°†åˆ›é€ è¶…è¿‡10ä¸‡ä¸ªå°±ä¸šå²—ä½ï¼Œæ¨åŠ¨ä¸­å›½æ•°å­—ç»æµå‘å±•ã€‚
                """,
                "expected_entities": ["é˜¿é‡Œå·´å·´", "å¼ å‹‡", "æ¸…åå¤§å­¦", "åŒ—äº¬å¤§å­¦", "ä¸­å›½"],
                "expected_relationships": ["æŠ•èµ„", "åˆä½œ", "åˆ›é€ "]
            },
            {
                "name": "Chinese Technical Document",
                "content": """
                æ·±åº¦å­¦ä¹ æŠ€æœ¯åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå–å¾—é‡å¤§çªç ´ã€‚
                Transformeræ¶æ„åœ¨æœºå™¨ç¿»è¯‘ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚
                è°·æ­Œã€å¾®è½¯ã€ç™¾åº¦ç­‰å…¬å¸éƒ½åœ¨ç§¯æå¼€å‘å¤§è¯­è¨€æ¨¡å‹ã€‚
                GPTå’ŒBERTç­‰æ¨¡å‹åœ¨ä¸­æ–‡æ–‡æœ¬ç†è§£æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚
                """,
                "expected_entities": ["æ·±åº¦å­¦ä¹ ", "Transformer", "è°·æ­Œ", "å¾®è½¯", "ç™¾åº¦", "GPT", "BERT"],
                "expected_relationships": ["çªç ´", "å¼€å‘", "è¡¨ç°"]
            },
            {
                "name": "Chinese Business Report",
                "content": """
                åä¸ºæŠ€æœ¯æœ‰é™å…¬å¸å‘å¸ƒ2024å¹´ç¬¬ä¸€å­£åº¦è´¢æŠ¥ï¼Œè¥æ”¶åŒæ¯”å¢é•¿15%ã€‚
                å…¬å¸è½®å€¼è‘£äº‹é•¿å¾ç›´å†›è¡¨ç¤ºï¼Œ5GæŠ€æœ¯å’Œäº‘è®¡ç®—ä¸šåŠ¡å¢é•¿å¼ºåŠ²ã€‚
                åœ¨æ¬§æ´²å¸‚åœºï¼Œåä¸ºä¸å¾·å›½ç”µä¿¡ã€æ³•å›½Orangeç­‰è¿è¥å•†ä¿æŒè‰¯å¥½åˆä½œå…³ç³»ã€‚
                é¢„è®¡å…¨å¹´è¥æ”¶å°†çªç ´8000äº¿å…ƒäººæ°‘å¸ã€‚
                """,
                "expected_entities": ["åä¸º", "å¾ç›´å†›", "å¾·å›½ç”µä¿¡", "æ³•å›½Orange", "æ¬§æ´²"],
                "expected_relationships": ["å‘å¸ƒ", "åˆä½œ", "å¢é•¿"]
            },
            {
                "name": "Chinese Academic Paper",
                "content": """
                ä¸­å›½ç§‘å­¦é™¢è®¡ç®—æŠ€æœ¯ç ”ç©¶æ‰€çš„ç ”ç©¶å›¢é˜Ÿåœ¨é‡å­è®¡ç®—é¢†åŸŸå–å¾—é‡è¦è¿›å±•ã€‚
                è¯¥å›¢é˜Ÿç”±æå›½æ°é™¢å£«é¢†å¯¼ï¼Œåœ¨é‡å­ç®—æ³•ä¼˜åŒ–æ–¹é¢æå‡ºåˆ›æ–°æ–¹æ³•ã€‚
                ç ”ç©¶æˆæœå·²å‘è¡¨åœ¨ã€ŠNatureã€‹å’Œã€ŠScienceã€‹ç­‰å›½é™…é¡¶çº§æœŸåˆŠã€‚
                è¯¥æŠ€æœ¯æœ‰æœ›åœ¨å¯†ç å­¦ã€è¯ç‰©ç ”å‘ç­‰é¢†åŸŸäº§ç”Ÿé‡å¤§å½±å“ã€‚
                """,
                "expected_entities": ["ä¸­å›½ç§‘å­¦é™¢", "æå›½æ°", "Nature", "Science"],
                "expected_relationships": ["ç ”ç©¶", "å‘è¡¨", "å½±å“"]
            }
        ]
        
        results = {}
        
        for i, test_case in enumerate(chinese_test_cases, 1):
            print(f"\nğŸ“ Test Case {i}: {test_case['name']}")
            print(f"ğŸ“„ Content: {test_case['content'][:100]}...")
            
            try:
                # Create analysis request
                request = AnalysisRequest(
                    data_type=DataType.TEXT,
                    content=test_case['content'],
                    language="zh"
                )
                
                # Process the content
                start_time = time.time()
                result = await self.agent.process(request)
                processing_time = time.time() - start_time
                
                # Extract results
                json_data = result.content[0].get("json", {})
                entities = json_data.get("entities", [])
                relationships = json_data.get("relationships", [])
                
                # Analyze results
                extracted_entity_names = [e.get("name", "") for e in entities]
                extracted_relationship_types = [r.get("relationship_type", "") for r in relationships]
                
                # Calculate accuracy
                entity_accuracy = self._calculate_entity_accuracy(
                    extracted_entity_names, test_case["expected_entities"]
                )
                relationship_accuracy = self._calculate_relationship_accuracy(
                    extracted_relationship_types, test_case["expected_relationships"]
                )
                
                results[test_case["name"]] = {
                    "success": entity_accuracy > 0.3,  # 30% threshold
                    "entity_accuracy": entity_accuracy,
                    "relationship_accuracy": relationship_accuracy,
                    "entities_found": len(entities),
                    "relationships_found": len(relationships),
                    "processing_time": processing_time,
                    "extracted_entities": extracted_entity_names,
                    "extracted_relationships": extracted_relationship_types
                }
                
                print(f"âœ… Entities: {len(entities)} found, Accuracy: {entity_accuracy:.2%}")
                print(f"âœ… Relationships: {len(relationships)} found, Accuracy: {relationship_accuracy:.2%}")
                print(f"â±ï¸  Processing time: {processing_time:.2f}s")
                
            except Exception as e:
                print(f"âŒ Error processing test case: {e}")
                results[test_case["name"]] = {
                    "success": False,
                    "error": str(e)
                }
        
        self.results["chinese_content_test_cases"] = results
        return results
    
    async def test_6_2_language_detection_accuracy(self) -> Dict:
        """Task 6.2: Test language detection accuracy."""
        print("\nğŸ§ª Task 6.2: Testing Language Detection Accuracy")
        print("=" * 60)
        
        # Test cases with known languages
        language_test_cases = [
            {
                "language": "zh",
                "content": "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œæ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«é¢†åŸŸå–å¾—é‡å¤§çªç ´ã€‚",
                "name": "Chinese Text"
            },
            {
                "language": "en", 
                "content": "Artificial intelligence technology is developing rapidly, with deep learning achieving breakthroughs in image recognition.",
                "name": "English Text"
            },
            {
                "language": "ja",
                "content": "äººå·¥çŸ¥èƒ½æŠ€è¡“ãŒæ€¥é€Ÿã«ç™ºå±•ã—ã¦ãŠã‚Šã€ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãŒç”»åƒèªè­˜åˆ†é‡ã§å¤§ããªãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã‚’é”æˆã—ã¦ã„ã¾ã™ã€‚",
                "name": "Japanese Text"
            },
            {
                "language": "ko",
                "content": "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìœ¼ë©°, ë”¥ëŸ¬ë‹ì´ ì´ë¯¸ì§€ ì¸ì‹ ë¶„ì•¼ì—ì„œ í° ëŒíŒŒêµ¬ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.",
                "name": "Korean Text"
            },
            {
                "language": "es",
                "content": "La tecnologÃ­a de inteligencia artificial se estÃ¡ desarrollando rÃ¡pidamente, con el aprendizaje profundo logrando avances en el reconocimiento de imÃ¡genes.",
                "name": "Spanish Text"
            },
            {
                "language": "fr",
                "content": "La technologie d'intelligence artificielle se dÃ©veloppe rapidement, avec l'apprentissage profond rÃ©alisant des percÃ©es dans la reconnaissance d'images.",
                "name": "French Text"
            }
        ]
        
        results = {}
        total_accuracy = 0
        
        for test_case in language_test_cases:
            print(f"\nğŸ” Testing: {test_case['name']}")
            
            try:
                # Create request with auto language detection
                request = AnalysisRequest(
                    data_type=DataType.TEXT,
                    content=test_case["content"],
                    language="auto"
                )
                
                # Extract text content (triggers language detection)
                await self.agent._extract_text_content(request)
                
                # Check if language was detected correctly
                detected_language = request.language
                expected_language = test_case["language"]
                is_correct = detected_language == expected_language
                
                results[test_case["name"]] = {
                    "success": is_correct,
                    "expected": expected_language,
                    "detected": detected_language,
                    "correct": is_correct
                }
                
                status = "âœ…" if is_correct else "âŒ"
                print(f"{status} Expected: {expected_language}, Detected: {detected_language}")
                
                if is_correct:
                    total_accuracy += 1
                    
            except Exception as e:
                print(f"âŒ Error in language detection: {e}")
                results[test_case["name"]] = {
                    "success": False,
                    "error": str(e)
                }
        
        overall_accuracy = total_accuracy / len(language_test_cases)
        print(f"\nğŸ“Š Overall Language Detection Accuracy: {overall_accuracy:.2%}")
        
        self.results["language_detection_accuracy"] = {
            "overall_accuracy": overall_accuracy,
            "detailed_results": results
        }
        return self.results["language_detection_accuracy"]
    
    async def test_6_3_validate_entity_extraction_chinese(self) -> Dict:
        """Task 6.3: Validate entity extraction in Chinese."""
        print("\nğŸ§ª Task 6.3: Validating Entity Extraction in Chinese")
        print("=" * 60)
        
        # Chinese entity extraction test cases
        chinese_entity_tests = [
            {
                "name": "Person Names",
                "text": "ä¹ è¿‘å¹³ä¸»å¸­ã€æå…‹å¼ºæ€»ç†ã€ç‹æ¯…å¤–é•¿å‡ºå¸­äº†ä¼šè®®ã€‚",
                "expected_entities": ["ä¹ è¿‘å¹³", "æå…‹å¼º", "ç‹æ¯…"],
                "expected_types": ["PERSON"]
            },
            {
                "name": "Organizations",
                "text": "æ¸…åå¤§å­¦ã€åŒ—äº¬å¤§å­¦ã€ä¸­ç§‘é™¢ã€åä¸ºå…¬å¸éƒ½æ˜¯çŸ¥åæœºæ„ã€‚",
                "expected_entities": ["æ¸…åå¤§å­¦", "åŒ—äº¬å¤§å­¦", "ä¸­ç§‘é™¢", "åä¸º"],
                "expected_types": ["ORGANIZATION"]
            },
            {
                "name": "Locations",
                "text": "åŒ—äº¬ã€ä¸Šæµ·ã€æ·±åœ³ã€å¹¿å·æ˜¯ä¸­å›½çš„ä¸»è¦åŸå¸‚ã€‚",
                "expected_entities": ["åŒ—äº¬", "ä¸Šæµ·", "æ·±åœ³", "å¹¿å·"],
                "expected_types": ["LOCATION"]
            },
            {
                "name": "Mixed Entities",
                "text": "é©¬äº‘åœ¨æ­å·åˆ›ç«‹äº†é˜¿é‡Œå·´å·´é›†å›¢ï¼Œè¯¥å…¬å¸æ€»éƒ¨ä½äºåŒ—äº¬ã€‚",
                "expected_entities": ["é©¬äº‘", "æ­å·", "é˜¿é‡Œå·´å·´", "åŒ—äº¬"],
                "expected_types": ["PERSON", "LOCATION", "ORGANIZATION"]
            }
        ]
        
        results = {}
        total_accuracy = 0
        
        for test_case in chinese_entity_tests:
            print(f"\nğŸ” Testing: {test_case['name']}")
            print(f"ğŸ“ Text: {test_case['text']}")
            
            try:
                # Extract entities
                result = await self.agent.extract_entities(test_case["text"], "zh")
                json_data = result.get("content", [{}])[0].get("json", {})
                entities = json_data.get("entities", [])
                
                # Analyze results
                extracted_names = [e.get("name", "") for e in entities]
                extracted_types = [e.get("type", "") for e in entities]
                
                # Calculate accuracy
                name_accuracy = self._calculate_entity_accuracy(
                    extracted_names, test_case["expected_entities"]
                )
                type_accuracy = self._calculate_type_accuracy(
                    extracted_types, test_case["expected_types"]
                )
                
                overall_accuracy = (name_accuracy + type_accuracy) / 2
                total_accuracy += overall_accuracy
                
                results[test_case["name"]] = {
                    "success": overall_accuracy > 0.4,  # 40% threshold
                    "name_accuracy": name_accuracy,
                    "type_accuracy": type_accuracy,
                    "overall_accuracy": overall_accuracy,
                    "entities_found": len(entities),
                    "extracted_entities": extracted_names,
                    "extracted_types": extracted_types
                }
                
                print(f"âœ… Name Accuracy: {name_accuracy:.2%}")
                print(f"âœ… Type Accuracy: {type_accuracy:.2%}")
                print(f"âœ… Overall Accuracy: {overall_accuracy:.2%}")
                
            except Exception as e:
                print(f"âŒ Error in entity extraction: {e}")
                results[test_case["name"]] = {
                    "success": False,
                    "error": str(e)
                }
        
        avg_accuracy = total_accuracy / len(chinese_entity_tests)
        print(f"\nğŸ“Š Average Chinese Entity Extraction Accuracy: {avg_accuracy:.2%}")
        
        self.results["chinese_entity_extraction"] = {
            "average_accuracy": avg_accuracy,
            "detailed_results": results
        }
        return self.results["chinese_entity_extraction"]
    
    async def test_6_4_query_translation_accuracy(self) -> Dict:
        """Task 6.4: Test query translation accuracy."""
        print("\nğŸ§ª Task 6.4: Testing Query Translation Accuracy")
        print("=" * 60)
        
        # Test query translation scenarios
        translation_test_cases = [
            {
                "name": "Chinese to English Query",
                "query": "äººå·¥æ™ºèƒ½æŠ€æœ¯æœ‰å“ªäº›åº”ç”¨ï¼Ÿ",
                "expected_english": "What are the applications of artificial intelligence technology?",
                "target_language": "en"
            },
            {
                "name": "English to Chinese Query", 
                "query": "What companies are working on AI?",
                "expected_chinese": "å“ªäº›å…¬å¸åœ¨ç ”ç©¶äººå·¥æ™ºèƒ½ï¼Ÿ",
                "target_language": "zh"
            },
            {
                "name": "Technical Query Translation",
                "query": "æ·±åº¦å­¦ä¹ åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨",
                "expected_english": "Applications of deep learning in healthcare",
                "target_language": "en"
            }
        ]
        
        results = {}
        
        for test_case in translation_test_cases:
            print(f"\nğŸ” Testing: {test_case['name']}")
            print(f"ğŸ“ Query: {test_case['query']}")
            
            try:
                # Test query translation
                start_time = time.time()
                result = await self.agent.query_knowledge_graph(
                    test_case["query"], 
                    test_case["target_language"]
                )
                translation_time = time.time() - start_time
                
                # Extract translated query from result
                translated_query = result.get("translated_query", "")
                
                results[test_case["name"]] = {
                    "success": True,
                    "original_query": test_case["query"],
                    "translated_query": translated_query,
                    "expected_translation": test_case.get(f"expected_{test_case['target_language']}", ""),
                    "translation_time": translation_time,
                    "has_results": len(result.get("entities", [])) > 0
                }
                
                print(f"âœ… Translation time: {translation_time:.2f}s")
                print(f"âœ… Has results: {results[test_case['name']]['has_results']}")
                
            except Exception as e:
                print(f"âŒ Error in query translation: {e}")
                results[test_case["name"]] = {
                    "success": False,
                    "error": str(e)
                }
        
        self.results["query_translation_accuracy"] = results
        return results
    
    async def test_6_5_performance_testing(self) -> Dict:
        """Task 6.5: Performance testing with large multilingual datasets."""
        print("\nğŸ§ª Task 6.5: Performance Testing with Large Multilingual Datasets")
        print("=" * 60)
        
        # Create large test dataset
        large_chinese_text = """
        äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å„ä¸ªé¢†åŸŸå¿«é€Ÿå‘å±•ã€‚åœ¨åŒ»ç–—å¥åº·é¢†åŸŸï¼ŒAIæŠ€æœ¯è¢«ç”¨äºç–¾ç—…è¯Šæ–­ã€è¯ç‰©ç ”å‘å’Œä¸ªæ€§åŒ–æ²»ç–—æ–¹æ¡ˆåˆ¶å®šã€‚
        åœ¨é‡‘èé¢†åŸŸï¼Œæœºå™¨å­¦ä¹ ç®—æ³•è¢«ç”¨äºé£é™©è¯„ä¼°ã€æ¬ºè¯ˆæ£€æµ‹å’ŒæŠ•èµ„å†³ç­–æ”¯æŒã€‚åœ¨æ•™è‚²é¢†åŸŸï¼Œæ™ºèƒ½æ•™è‚²å¹³å°æä¾›ä¸ªæ€§åŒ–å­¦ä¹ ä½“éªŒã€‚
        
        ä¸­å›½çš„ä¸»è¦ç§‘æŠ€å…¬å¸åŒ…æ‹¬é˜¿é‡Œå·´å·´ã€è…¾è®¯ã€ç™¾åº¦ã€åä¸ºç­‰ã€‚è¿™äº›å…¬å¸åœ¨äº‘è®¡ç®—ã€å¤§æ•°æ®ã€ç‰©è”ç½‘ç­‰é¢†åŸŸéƒ½æœ‰é‡è¦å¸ƒå±€ã€‚
        æ¸…åå¤§å­¦ã€åŒ—äº¬å¤§å­¦ã€ä¸­ç§‘é™¢ç­‰ç ”ç©¶æœºæ„åœ¨åŸºç¡€ç ”ç©¶æ–¹é¢åšå‡ºäº†é‡è¦è´¡çŒ®ã€‚
        
        åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œç™¾åº¦Apolloã€ç‰¹æ–¯æ‹‰ã€Waymoç­‰å…¬å¸éƒ½åœ¨ç§¯æå¼€å‘ç›¸å…³æŠ€æœ¯ã€‚è¿™äº›æŠ€æœ¯å°†å½»åº•æ”¹å˜äº¤é€šè¿è¾“æ–¹å¼ã€‚
        åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼ŒGPTã€BERTã€Transformerç­‰æ¨¡å‹åœ¨æ–‡æœ¬ç†è§£å’Œç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ã€‚
        
        é‡å­è®¡ç®—æ˜¯æœªæ¥è®¡ç®—æŠ€æœ¯çš„é‡è¦æ–¹å‘ã€‚è°·æ­Œã€IBMã€å¾®è½¯ç­‰å…¬å¸éƒ½åœ¨ç§¯ææŠ•å…¥é‡å­è®¡ç®—ç ”ç©¶ã€‚
        ä¸­å›½ä¹Ÿåœ¨é‡å­é€šä¿¡å’Œé‡å­è®¡ç®—æ–¹é¢å–å¾—äº†é‡è¦è¿›å±•ï¼Œæ½˜å»ºä¼Ÿé™¢å£«å›¢é˜Ÿåœ¨é‡å­é€šä¿¡é¢†åŸŸå¤„äºä¸–ç•Œé¢†å…ˆåœ°ä½ã€‚
        """ * 3  # Repeat to create larger dataset
        
        performance_metrics = {}
        
        # Test processing time
        print("â±ï¸  Testing processing performance...")
        start_time = time.time()
        
        try:
            request = AnalysisRequest(
                data_type=DataType.TEXT,
                content=large_chinese_text,
                language="zh"
            )
            
            result = await self.agent.process(request)
            processing_time = time.time() - start_time
            
            # Extract metrics
            json_data = result.content[0].get("json", {})
            entities_count = len(json_data.get("entities", []))
            relationships_count = len(json_data.get("relationships", []))
            
            performance_metrics = {
                "success": True,
                "processing_time": processing_time,
                "text_length": len(large_chinese_text),
                "entities_extracted": entities_count,
                "relationships_extracted": relationships_count,
                "processing_speed": len(large_chinese_text) / processing_time,  # chars per second
                "entities_per_second": entities_count / processing_time,
                "relationships_per_second": relationships_count / processing_time
            }
            
            print(f"âœ… Processing time: {processing_time:.2f}s")
            print(f"âœ… Text length: {len(large_chinese_text)} characters")
            print(f"âœ… Entities extracted: {entities_count}")
            print(f"âœ… Relationships extracted: {relationships_count}")
            print(f"âœ… Processing speed: {performance_metrics['processing_speed']:.0f} chars/sec")
            
        except Exception as e:
            print(f"âŒ Performance test failed: {e}")
            performance_metrics = {
                "success": False,
                "error": str(e)
            }
        
        # Test memory usage (basic estimation)
        import psutil
        process = psutil.Process()
        memory_usage = process.memory_info().rss / 1024 / 1024  # MB
        performance_metrics["memory_usage_mb"] = memory_usage
        
        print(f"ğŸ’¾ Memory usage: {memory_usage:.1f} MB")
        
        self.results["performance_testing"] = performance_metrics
        return performance_metrics
    
    async def test_6_6_integration_testing(self) -> Dict:
        """Task 6.6: Integration testing with other agents."""
        print("\nğŸ§ª Task 6.6: Integration Testing with Other Agents")
        print("=" * 60)
        
        integration_results = {}
        
        # Test with translation service
        print("ğŸ”„ Testing Translation Service Integration...")
        try:
            chinese_text = "äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•è¿…é€Ÿ"
            translation_result = await self.agent.translation_service.translate_text(
                chinese_text, target_language="en"
            )
            
            integration_results["translation_service"] = {
                "success": True,
                "original": chinese_text,
                "translated": translation_result.translated_text,
                "confidence": getattr(translation_result, 'confidence', 0.0)
            }
            print(f"âœ… Translation: '{chinese_text}' -> '{translation_result.translated_text}'")
            
        except Exception as e:
            print(f"âŒ Translation service integration failed: {e}")
            integration_results["translation_service"] = {
                "success": False,
                "error": str(e)
            }
        
        # Test graph report generation
        print("ğŸ“Š Testing Graph Report Generation...")
        try:
            report_result = await self.agent.generate_graph_report(target_language="zh")
            
            integration_results["graph_report_generation"] = {
                "success": True,
                "has_content": len(report_result.get("content", [])) > 0,
                "target_language": "zh"
            }
            print("âœ… Graph report generation successful")
            
        except Exception as e:
            print(f"âŒ Graph report generation failed: {e}")
            integration_results["graph_report_generation"] = {
                "success": False,
                "error": str(e)
            }
        
        # Test query functionality
        print("ğŸ” Testing Query Functionality...")
        try:
            query_result = await self.agent.query_knowledge_graph("äººå·¥æ™ºèƒ½", target_language="zh")
            
            integration_results["query_functionality"] = {
                "success": True,
                "has_results": len(query_result.get("entities", [])) > 0,
                "query_language": "zh"
            }
            print("âœ… Query functionality successful")
            
        except Exception as e:
            print(f"âŒ Query functionality failed: {e}")
            integration_results["query_functionality"] = {
                "success": False,
                "error": str(e)
            }
        
        self.results["integration_testing"] = integration_results
        return integration_results
    
    def _calculate_entity_accuracy(self, extracted: List[str], expected: List[str]) -> float:
        """Calculate accuracy of entity extraction."""
        if not expected:
            return 1.0
        
        found_count = 0
        for expected_entity in expected:
            for extracted_entity in extracted:
                if (expected_entity.lower() in extracted_entity.lower() or 
                    extracted_entity.lower() in expected_entity.lower()):
                    found_count += 1
                    break
        
        return found_count / len(expected)
    
    def _calculate_relationship_accuracy(self, extracted: List[str], expected: List[str]) -> float:
        """Calculate accuracy of relationship extraction."""
        return self._calculate_entity_accuracy(extracted, expected)
    
    def _calculate_type_accuracy(self, extracted_types: List[str], expected_types: List[str]) -> float:
        """Calculate accuracy of entity type classification."""
        if not expected_types:
            return 1.0
        
        # Check if any of the expected types are found in extracted types
        found_count = 0
        for expected_type in expected_types:
            if expected_type in extracted_types:
                found_count += 1
        
        return found_count / len(expected_types)
    
    async def run_all_tests(self) -> Dict:
        """Run all Phase 6 tests."""
        print("ğŸš€ Starting Phase 6: Comprehensive Testing & Validation")
        print("=" * 80)
        
        test_functions = [
            ("6.1 Chinese Content Test Cases", self.test_6_1_chinese_content_test_cases),
            ("6.2 Language Detection Accuracy", self.test_6_2_language_detection_accuracy),
            ("6.3 Chinese Entity Extraction Validation", self.test_6_3_validate_entity_extraction_chinese),
            ("6.4 Query Translation Accuracy", self.test_6_4_query_translation_accuracy),
            ("6.5 Performance Testing", self.test_6_5_performance_testing),
            ("6.6 Integration Testing", self.test_6_6_integration_testing)
        ]
        
        for test_name, test_func in test_functions:
            try:
                await test_func()
            except Exception as e:
                print(f"âŒ {test_name} failed with error: {e}")
                self.results[test_name.lower().replace(" ", "_")] = {
                    "success": False,
                    "error": str(e)
                }
        
        # Generate summary
        self._generate_summary()
        
        return self.results
    
    def _generate_summary(self):
        """Generate comprehensive test summary."""
        print("\n" + "=" * 80)
        print("ğŸ“Š PHASE 6 TEST SUMMARY")
        print("=" * 80)
        
        total_tests = 0
        passed_tests = 0
        
        for test_name, result in self.results.items():
            if isinstance(result, dict):
                if "success" in result:
                    total_tests += 1
                    if result["success"]:
                        passed_tests += 1
                        status = "âœ… PASS"
                    else:
                        status = "âŒ FAIL"
                    print(f"{status} - {test_name}")
                elif "overall_accuracy" in result:
                    print(f"ğŸ“ˆ {test_name}: {result['overall_accuracy']:.2%} accuracy")
                elif "average_accuracy" in result:
                    print(f"ğŸ“ˆ {test_name}: {result['average_accuracy']:.2%} accuracy")
        
        print(f"\nğŸ¯ Overall Results: {passed_tests}/{total_tests} tests passed")
        
        if passed_tests == total_tests:
            print("ğŸ‰ All Phase 6 tests passed! Multilingual functionality is working correctly.")
        else:
            print("âš ï¸  Some tests failed. Please review the implementation.")


async def main():
    """Run the Phase 6 test suite."""
    test_suite = Phase6TestSuite()
    results = await test_suite.run_all_tests()
    
    # Save results to file
    output_file = Path("Test/phase6_test_results.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ Test results saved to: {output_file}")
    
    return results


if __name__ == "__main__":
    asyncio.run(main())
