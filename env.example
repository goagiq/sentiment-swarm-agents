# Model Configuration
# Primary models for different tasks
TEXT_MODEL=ollama:mistral-small3.1:latest
VISION_MODEL=ollama:llava:latest

# Fallback models when primary models fail
FALLBACK_TEXT_MODEL=ollama:llama3.2:latest
FALLBACK_VISION_MODEL=ollama:granite3.2-vision

# Ollama server configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_TIMEOUT=30

# Model parameters
TEXT_TEMPERATURE=0.1
TEXT_MAX_TOKENS=200
VISION_TEMPERATURE=0.7
VISION_MAX_TOKENS=200

# Tool calling configuration
ENABLE_TOOL_CALLING=true
MAX_TOOL_CALLS=5

# Example configurations for different setups:

# For development with local Ollama:
# TEXT_MODEL=ollama:mistral-small3.1:latest
# VISION_MODEL=ollama:llava:latest
# OLLAMA_HOST=http://localhost:11434

# For production with remote Ollama:
# TEXT_MODEL=ollama:llama3.2:latest
# VISION_MODEL=ollama:granite3.2-vision
# OLLAMA_HOST=http://your-ollama-server:11434

# For testing with different models:
# TEXT_MODEL=ollama:phi3:mini
# VISION_MODEL=ollama:llava:latest
# OLLAMA_HOST=http://localhost:11434
